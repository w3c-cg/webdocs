# W3C Docs CG and W3C TAG session at TPAC, Kobe, Japan, 2025-11-10

Attendees: Jeffrey Yaskin, Dan Appelquist, Florian Scholz, Will Bamberg, Hadley Beman, Lola Odelola, François Daoust, Brian Kardel, Rachel Andrew, Estelle W., Matthew Atkinson, Vadim, Chris (Chomium, PNG) ? ? ?

https://www.w3.org/events/meetings/cb1431ba-d0d5-461c-9e5e-aab4c2da403f/

Slides: https://docs.google.com/presentation/d/1Gxk2-8_Rm1HDgSBeRUQHHtUDKalBKy8StlIuBGJ7BFA/edit?usp=drivesdk

Florian: We'd like to talk about explainers...  What we found is that explainer docs vary quite a lot...  Could be a new feature.. Could be a new concept, an entire new spec, can be very overwhelming. We also found that "if we can understand it then we can write docs... but if we can't understand it then the explainer isn't very good." We've seen explainers being fairly minimal... We were wondering if the author doesn't care... then what's "our job" - are we the completeness police?

Discussion questions:

* Who are we doing this for?
* What will be better as a result?
* We want to be helpful, not yet another process item.
* What parts of the explainer doc are we responsible for?
* How does this fit into the overall reviewing process?

Jeffrey: when, do you document things?
...

BrianL: standards track? Do you exclude WICG thing?

Will: In practice, no... not on MDN. Can be incubation as well.

Hadley: when we first started asking for explainers, there was resistance because it's extra work. At the same time, I worry that if we go too far to make explainers useful in other contexts then we might make it even more work. People want to spent time working on their feature. Wanted to highlight that as a potential risk.

Lola: Not talking about expanding explainers in any significant way.  So far it's kind of been more like "is there scope to review explainers that lessens TAG's load and if there is what does that look like?" There's a checklist that I've proposed:

> Explainer review checklist, proposed by Lola
> https://github.com/w3c-cg/webdocs/issues/21
>
> Section completeness
> * Code examples:
>   * Are they syntactically correct (at least plausible JS)?
>   * Do they illustrate use cases, not just API shape?
> * Diagrams properly labelled (alt-text or caption)
> * Links point to correct locations
> * First time reader accessibility, i.e. can someone outside of the space understand what is being proposed and why?*

Lola: not sure we [TAG] can avoid people being annoying...

Florian: it's not the goal to be annoying.. unless annoying comes with some benefits... Use cases e.g. so useful. I think there are good benefits from writing a technical explainer.

Vadmin: there is usefulness in this initiative (requiring one implementation) ... there are often no use cases and code examples. I know a few examples where explainer was a good source of docunentation for MDN. A well-written explainer really helps. There are examples where something has shipped in a browser and still no MDN article so it helps.

Matthew: "what is an explainer and what's it for" - i liked the time about first-time reader accessibility. Why is it important? One of the key purposes from TAG pov is to help reviewers to understand the trade-offs that were made when something is being designed. Why are we doing it? what are we doing it? what were the trade-offs? Also: we would expect some things to move form the explainer to the spec... But some things would stay in the explainer (e.g. "we thought about xyz but decided abc"). I have had some feedback from APA - use of the term non-goals. I read it as "out of scope" .. is it more deliberate?

Jeffrey: sometimes gets used as "hard out of scope." 

Hadley: "that's not what we're talking about and we're definitely not going to do that."

Jeffrey: as TAG I would love people to review explainers... But the group should be doing things that further this group's goals. So what ensures that you can write documentation later in the process when you need to write documentation.

Brian: In WICG, even before something is adopted, people create explainers. I don't know that everyone is great at writing one. A lot of people who write them would love immediate feedback. Maybe that's something that would help. Getting quick feedback would be very valuable. Most people are not technical writers. The earlier we get then corrected the better. If the DocsCG can do that, great!

Lola: We're a small group...

Rachel: question I had was around timing - I used to do all the chrome first docs... would quite often find that the explainer, spec and docs would be out of sync. We write docs when things go to Beta. If at that point, if the spec is different from the spec then it's misleading.

Florian: I agree ... also we discussed the lifecycle of explainers. Merging with the spec might help with the lifecycle of it... MS have an index of their explainers with different statuses. In reviewing explainers we can bring in the lens of the web developer... that might help to shape. Process of reviewing... We need to take time to review on the calls... More help appreciated. We get through 5-6 a call...

...

Estelle: instead of having DOCS CG go over it, would a TAG member be better to guide the explainer... maybe a mentor?  If one person was assigned...

... discussion of how to get people quicker feedback ...

Estelle: should we add guidelines for updating explainers... Should we add it to the explainer process to add it to explainer explainer?

Matthew: it's in the explainer explainer...

François: With specs we also have the problem with outdated info... We extract info into wpt ... some tests fail so you get insensitive to tests... Feedback loop.

Chris: sometimes we make a live demo and then update the explainer to just link to that.  Also what would trigger a re-review?

Lola: spec authors are generally good at notifying when we should re-review. There is an incentive with TAG ,,, We'd need a trigger for automated check.

Will: is there a general expectation that explainers are reviewed / kept in sync?

Jeffrey: there's a hope.

Lola: some implementers are better at doing so than others.

Jeffrey: explainers have a more detailed lifecycle. Mozilla have a good example. Ideally the explainers are short...  There are a couple of lifecycle points that would make sense to hook into. For Chromium it's Dev trial, origin trial, TAG review... For Mozilla and Safari I don't think there as many.

Matthew: also where should explainers be put? Different orgs and groups have different practices. They can easily get forgtten.

Jeffrey: about testing explainers: we don't have good ways of embedding external content since they are just markdown files... This is a good reason to encourage people to move code examples into the spec.

Hadley: on the lifecycle thing we have tried to keep off the w3c process. However speaking as a chair, when arriving at a transition point, I arrive at the Process... We could add "you may wish to add an explainer, update the explainer."

Dan: I raised the issue in the AB member-only repo to ask to make explainers a more formal thing. One of the original goals of the explainers was to make it easy to write something that's useful for developers next to your code, your spec. There are competing tensions. From a W3C process standpoint, and we're talking about Process in the AB, the TAG review does not appear in the Process. In the Process process, we're trying to figure out where the Explainer's explainer is going to fit.

Lola: answering the key questions - actionable things.. a desire fot docs cg to do explainer reviews... a question that has arisen in this group... What does that look like in practice... Do we monitor the TAG review queue? Do we need to respond to people even if they haven't asked for review.

Jeffrey: it's not only the TAG who gets to review specs and gets to feed back. Anyone could file issues... If Docs CG monitor the TAG design reviews we might be duplicating work. It's probably better for Docs CG to chime in earlier. When the explainer is submitted to the repo. They still get submitted before TAG review happens. If Docs CG watches those repos they could do quick review... doc quality review ... would save TAG time.  I can point to those repositories...

Florian: we've also found ourselves... having our own checklist... not looking at the technical details but more "how well is it explained."

Estelle: if that happens the Docs CG needs to have a point where it [hands over] to TAG.

Lola: leaves us when it gets to TAG?

Estelle: I'm thinking "we've given feedback and they haven't fixed..."

*discussion on why docs cg asked to proactive outreach*

*are DocsCG reviews useful enough to be considered part of horizontal review?*

Florian: sometimes when I have feedback on a spec it's too late...

Hadley: lots of TAG reviews.

Matthew: in APA sometimes the feature has shipped a year ago before we see it... It's a universal problem. Some work in the W3C team around incubation and adoption. How do we know what's important to review?

Jeffrey: sometimes if you want to have an effect you need to go out and proactively seek...

Lola: we don't look at things if they are missing significant sections...

Dan: Jeffrey's suggestion to be proactive implies that things get discussed in specific places that can be watched, and we've had various cases where things came from individual repos.

Jeffrey: I think we've fixed that.

Bryan: There are cases where proposals get raised in issues.

Jeffrey: That's right, we should push back on this when the proposal should need an explainer.

Lola: If TAG receives a request for a review of an explainer that comes from an untracked repo, it could redirect to the Docs CG.

Florian: What's the bar for creating an explainer?

Hadley: Historically, that's whatever you want a TAG review for.

Lola: example of webaudio... some groups asking for review for small changes... 

## Next steps

Florian: What are the places that we can observe ... let's observe for a while... and submit feedback to those places..